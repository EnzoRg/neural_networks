{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRYEofSD0xoF"
   },
   "source": [
    "# Perceptrón multicapa\n",
    "\n",
    "Consideraremos un perceptrón multicapa, con capas enumeradas por $l=0,1,...,L$. Denotemos por $x^l_i$ el estado de la $i$-ésima neurona en la capa $l$. Diremos que la red posee $n^l$ neuronas $i=1,...,n^l$ en la $l$-ésima capa. En particular, $x^0$ denota el vector de estados de la capa de entrada y $x^L$ el vector de estados de la capa de salida.\n",
    "Se tiene que\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "x^l_i\n",
    "=\n",
    "g(h^l_i)\n",
    "\\;\\;\\;\\;\\;\\;\\;\\; (1)\n",
    "\\end{equation}\n",
    "\n",
    "donde $g:\\mathbb{R}\\to \\mathbb{R}$ es una función de activación, por ejemplo una sigmoide $g(h)=1/(1+e^{-h})$, y\n",
    "\n",
    "\\begin{equation}\n",
    "h^{l}_i\n",
    "=\n",
    "\\sum_j w^{l}_{ij} x^{l-1}_j\n",
    "\\;\\;\\;\\;\\;\\;\\;\\; (2)\n",
    "\\end{equation}\n",
    "\n",
    "es el campo local sufrido por la $i$-ésima neurona en la $l$-ésima capa .\n",
    "Además, $w^l_{ij}$ denota la intensidad de la sinapsis que conecta la $j$-ésima neurona en la $(l-1)$-ésima capa con la $i$-ésima neurona en la $l$-ésima capa.\n",
    "Notar, la red depende de las matrices de pesos sinápticos $w^1,w^2,...,w^{L}$.\n",
    "\n",
    "## Umbrales de activación\n",
    "\n",
    "En cada una de las capas $l=0,1,...,L-1$, se agrega una neurona extra $i=n^l+1$ con un estado fijo $x^l_{n^l+1}=-1$. De esta manera, una nueva sinapsis $u^{l}_i:=w^{l}_{i,n^{l-1}+1}$ hace las veces de umbral de activación de la $i$-ésima neurona en la $l$-ésima capa, ya que\n",
    "\n",
    "\\begin{equation}\n",
    "h^{l+1}_i\n",
    "=\n",
    "w^{l+1}_{i,n^{l}+1} x^{l}_{n^{l}+1}\n",
    "+\n",
    "\\sum_{j=1}^{n^l} w^{l+1}_{ij} x^{l}_j\n",
    "=\n",
    "-\n",
    "u^{l+1}_i\n",
    "+\n",
    "\\sum_{j=1}^{n^l} w^{l+1}_{ij} x^l_j\n",
    "\\;\\;\\;\\;\\;\\;\\;\\; (3)\n",
    "\\end{equation}\n",
    "\n",
    "## Conjunto de entrenamiento\n",
    "\n",
    "Los datos de entrenamiento consisten en un conjunto de pares $\\{(e^m,s^m):m=1,...,M\\}$ donde $e^m\\in \\mathbb{R}^{n_0}$ y $s^m\\in \\mathbb{R}^{n_L}$ son vectores que representan el $m$-ésimo par de entrada-salida o *ejemplo* que debe aprender la red.\n",
    "\n",
    "## Función costo: el Error Cuadrático\n",
    "\n",
    "Si pensamos que la salida de la red es una función de la entrada, i.e. que $x^L(x^0)$, podemos evaluar el error que comete la red sobre el conjunto de entramiento utilizando el *error cuadrático*\n",
    "$$\n",
    "E\n",
    "=\n",
    "\\sum_{m=1}^M F^m\n",
    "$$\n",
    "como *función costo*, donde\n",
    "$$\n",
    "F^m\n",
    "=\n",
    "\\frac{1}{2}\n",
    "\\sum_{i=1}^{n^L}\n",
    "(x^L_i(x^0=e^m) - s^m_i)^2\n",
    "$$\n",
    "es el error cuadrático que comete la red sobre el $m$-ésimo ejemplo.\n",
    "\n",
    "## Entrenamiento: descenso por el gradiente\n",
    "\n",
    "Entrenar la red consisten en encontrar valores de los pesos sinápticos $w^l_{ij}$ que minimicen el error $E$.\n",
    "Para ello, expresamos el error en función de dichos pesos y calculamos las componentes de su gradiente\n",
    "$$\n",
    "\\frac{\\partial E}{\\partial w^l_{ij}}\n",
    "=\n",
    "\\sum_m\n",
    "\\frac{\\partial F^m}{\\partial w^l_{ij}}\n",
    "$$\n",
    "De esta manera, podemos utilizar el algoritmo de descenso por el gradiente para actualizar los pesos hasta que el error alcance un mínimo global.\n",
    "Más precisamente, partiendo de valores aleatorios\n",
    "$(w^l_{ij})^0$ para los pesos sinápticos, actualizamos iterativamente a los mismos con la siguiente regla\n",
    "\\begin{equation}\n",
    "(w^l_{ij})^{t+1} = (w^l_{ij})^t-\\eta \\frac{\\partial F^m}{\\partial w^l_{ij}}((w^l_{ij})^t)\n",
    "\\;\\;\\;\\;\\;\\;\\;\\; (4)\n",
    "\\end{equation}\n",
    "para todo $l$, $ij$ y $m$, donde el parámetro $0<\\eta\\ll 1$ controla la tasa de aprendizaje.\n",
    "La iteración se detiene cuando ya no se advierten reducciones significativas del error $E$.\n",
    "\n",
    "## Cálculo del gradiente del error cuadrático\n",
    "\n",
    "Con el fin de simplificar la notación, elegimos un valor arbitrario de $m$ y obviamos la dependencia de las expresiones con éste índice.\n",
    "\n",
    "Notar que los vectores $x^l$ y $h^l$ sólo dependen de las matrices $w^1,...,w^{l}$.\n",
    "De esta manera, observamos que\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial x^l_i}{\\partial w^r_{pq}}\n",
    "&=&\n",
    "g'(h^l_i)\n",
    "\\frac{\\partial h^l_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "si $r\\leq l$, y\n",
    "$$\n",
    "\\frac{\\partial x^l_i}{\\partial w^r_{pq}}=0\n",
    "$$\n",
    "\n",
    "en caso contrario.\n",
    "Por otro lado,\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial h^{l}_i}{\\partial w^r_{pq}}\n",
    "&=&\n",
    "\\frac{\\partial}{\\partial w^r_{pq}}\n",
    "\\bigg(\n",
    "\\sum_j w^{l}_{ij} x^{l-1}_j\n",
    "\\bigg)\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_j w^{l}_{ij}\n",
    "\\frac{\\partial x^{l-1}_j}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "si $r<l$, y\n",
    "$$\n",
    "\\frac{\\partial h^l_i}{\\partial w^{l}_{pq}}\n",
    "=\n",
    "\\sum_j\n",
    "\\delta_{ip}\n",
    "\\delta_{jq}\n",
    "x^{l-1}_j\n",
    "=\n",
    "\\delta_{ip}\n",
    "x^{l-1}_q\n",
    "$$\n",
    "Con estas ecuaciones se pueden establecer una relación de recurrencia que nos permite calcular las componentes del gradiente de $F$.\n",
    "A saber\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial F}{\\partial w^r_{pq}}\n",
    "&=&\n",
    "\\sum_i (x^L_i-s_i)\n",
    "\\frac{\\partial x^L}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_i (x^L_i-s_i)\n",
    "g'(h^L_i)\n",
    "\\frac{\\partial h^L_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_i\n",
    "D^L_i\n",
    "\\frac{\\partial h^L_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_i\n",
    "D^L_i\n",
    "\\sum_j\n",
    "w^L_{ij}\n",
    "\\frac{\\partial x^{L-1}_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_i\n",
    "D^L_i\n",
    "\\sum_j\n",
    "w^L_{ij}\n",
    "g'(h^{L-1}_j)\n",
    "\\frac{\\partial h^{L-1}_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_j\n",
    "\\bigg(\n",
    "g'(h^{L-1}_j)\n",
    "\\sum_i\n",
    "w^L_{ij}\n",
    "D^L_i\n",
    "\\bigg)\n",
    "\\frac{\\partial h^{L-1}_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_j\n",
    "D^{L-1}_j\n",
    "\\frac{\\partial h^{L-1}_i}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "donde\n",
    "\\begin{equation}\n",
    "D^L_i:=(x^L_i-s_i)g'(h^L_i)\n",
    "\\;\\;\\;\\;\\;\\;\\;\\; (5)\n",
    "\\end{equation}\n",
    "y\n",
    "$$\n",
    "D^{L-1}_j\n",
    ":=\n",
    "g'(h^{L-1}_j)\n",
    "\\sum_i\n",
    "w^L_{ij}\n",
    "D^L_i\n",
    "$$\n",
    "representan los *errores locales* de la $i$-ésima neurona en la $L$-ésima capa y la $j$-ésima neurona en la $(L-1)$-ésima capa, respectivamente.\n",
    "\n",
    "El anterior procedimiento puede continuarse capa por capa, con cada capa $l$ tal que $r<l$, de manera que\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial F}{\\partial w^r_{pq}}\n",
    "&=&\n",
    "\\sum_j D_j^l\n",
    "\\frac{\\partial h^l_j}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "donde\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "D_j^l\n",
    ":=\n",
    "g'(h^{l}_j)\n",
    "\\sum_i w^{l+1}_{ij}D_i^{l+1}\n",
    "\\;\\;\\;\\;\\;\\;\\;\\; (6)\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "hasta que eventualmente se alcanza la capa $l=r$, y se obtiene\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial F}{\\partial w^r_{pq}}\n",
    "&=&\n",
    "\\sum_j\n",
    "D_j^{r}\n",
    "\\frac{\\partial h^{r}_j}{\\partial w^r_{pq}}\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "\\sum_j\n",
    "D_j^{r}\n",
    "\\delta_{jp}\n",
    "x^{r-1}_q\n",
    "\\nonumber\n",
    "\\\\\n",
    "&=&\n",
    "D_p^{r}\n",
    "x^{r-1}_q\n",
    "\\nonumber\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "En particular, este último resultado se verifica para el caso $r=L$ de $pq$ arbitrario.\n",
    "También se verifica para el caso en que $q=n^{r-1}+1$ y valores arbitrarios de $r$ y $p$, en donde $x_q^{r-1}=-1$ corresponde al estado fijo de la neurona en la capa $(r-1)$-ésima que permite simular la acción de umbrales en la capa $r$-ésima, tal como se describe en la Ec. 3.\n",
    "\n",
    "## El algoritmo de backpropagation\n",
    "\n",
    "Los resultados anteriores pueden condensarse en el llamado *algoritmo de backpropagation*, el cuál permite el cálculo del gradiente y la actualización de los pesos sinápticos, y consiste en la siguiente lista de pasos.\n",
    "Para cada ejemplo $m=1,...,M$, ejecutar:\n",
    "1. *Forward pass:* calcular la salida $x^L$ de la red ante la entrada $x^1=e^m$ utilizando las Ecs. 1 y 2. En el proceso, guardar los valores de activación $x^l$ y de los correspondientes campos locales $h^l$ obtenidos en las distintas capas $l=2,...,L$, ya que serán útiles más adelante.\n",
    "2. Calcular el vector de errores $D^L$ de la capa de salida utilizando la Ec. 5.\n",
    "3. Propagar los errores hacia atrás, i.e. calcular los errores $D^l$ para $l=L-1,L-2,...,1$ utilizando la Ec. 6.\n",
    "4. Para cada $l$, $i$ y $j$, calcular el gradiente $\\frac{\\partial F^m}{\\partial w^l_{ij}}$ utilizando la Ec. 7 y actualizar el correspondiente peso sináptico $w^l_{ij}$ utilizando la Ec. 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XeWtDvx6C8A"
   },
   "source": [
    "## **Ejercicio 1**\n",
    "\n",
    "Genere un conjunto de entrenamiento compuesto por $M=\\sum_c m_c$ puntos en $\\mathbb{R}^{n_e}$ distribuidos en $n_s$ nubes de $m_c$ puntos.\n",
    "\n",
    "Para generar las nubes:\n",
    "\n",
    "* genere aleatoriamente $n_s$ puntos en $\\mathbb{R}^{n_e}$ a los que llamaremos centros, sorteando los valores de las coordenadas a partir de una distribución normal, y\n",
    "\n",
    "* para cada centro $c$, genere $m_c$ puntos aleatorios alrededor del mismo, sumando sus coordenadas a números aleatorios generados con una Gaussiana de varianza $\\sigma^2$.\n",
    "\n",
    "Las $n_e$ coordenadas del $m$-ésimo punto constituirán el vector de entrada del $m$-ésimo ejemplo.\n",
    "La nube a la que pertenece el $m$-ésimo punto determinará el vector de salida del $m$-ésimo ejemplo.\n",
    "Más precisamente, si el $m$-ésimo punto pertenence a la $c$-ésima nube, el vector de salida será el vector canónico $(0,0,...,1,...,0)$ de $n_s$ componentes con un único 1 en la $c$-esima posición.\n",
    "\n",
    "Concretamente\n",
    "\n",
    "1. Genere un conjunto de 8 puntos en $\\mathbb{R}^{n_e}$ con $n_e=2$, divididos en 3 nubes con $m_1=3$ en la primera nube, $m_2=2$ puntos en la segunda nube y $m_3=3$ puntos en la tercera nube. Utilice $\\sigma=0.1$ para indicar la dispersión de los puntos alrededor de cada nube.\n",
    "\n",
    "2. Grafique las nubes de puntos, utilizando un color distinto para cada una de ellas.\n",
    "\n",
    "## **Ejercicio 2**\n",
    "\n",
    "1. Implemente un **perceptrón multicapa** con $n_e=2$ neuronas de entrada, una capa oculta de $n_o=2$ neuronas, y una capa de salida de $n_s=3$ neuronas. Recuerde, además, agregar las neuroas auxiliares que se utiliza para imitar los umbrales de activación. Utilice funciones de activación **sigmoideas**.\n",
    "\n",
    "2. Entrenelo sobre el conjunto de ejemplos generado en el Ejercicio 1. Para entrenarlo, utilice una tasa $\\eta=0.02$ y alrededor de 10.000 de épocas o más, según considere necesario.\n",
    "\n",
    "3. Grafique el error $E$ en función del número de épocas de entrenamiento.\n",
    "\n",
    "4. Luego, grafique nuevamente los puntos del Ejercicio 1, pintando el relleno de los mismos con los colores correspondiente a cada nube, y el borde de los mismos con el color correspondiente a la predicción obtenida con el **perceptrón multicapa**. Coinciden las predicciones con los colores originales?\n",
    "\n",
    "5. Repita los experimentos con funciones de activación **ReLUs**. Que ocurre?\n",
    "\n",
    "## **Ejercicio 3: la compuerta XOR**\n",
    "\n",
    "1. Fabrique un dataset con el siguiente conjunto de 4 ejemplos:\n",
    "\n",
    "    * $e_1 = (0,0)$, $s_1=(1,0)$\n",
    "    * $e_2 = (0,1)$, $s_2=(0,1)$\n",
    "    * $e_3 = (1,0)$, $s_3=(0,1)$\n",
    "    * $e_4 = (1,1)$, $s_4=(1,0)$\n",
    "    \n",
    "  corresponde a la compuerta XOR.\n",
    "\n",
    "2. Es el **perceptrón multicapa** capáz de aprender la compuerta XOR? Para responder esta pregunta, genere un **perceptrón multicapa** con $n_e=2$ neuronas de entrada, $n_o=2$ neuronas ocultas y $n_s=2$ neuronas de salida, y entrénelo utilizando el conjunto de ejemplos de la compuerta XOR.\n",
    "\n",
    "3. Como se compara el **perceptrón multicapa** con el **perceptrón monocapa** sobre la compuerta XOR? Para responder esta otra pregunta, genere otro perceptrón \"multicapa\", pero esta vez utilizando solo dos capas, una de entrada con $n_e=2$ neuronas y una de salida con $n_s=2$ neuronas (de manera tal que en realidad es un perceptron monocapa), y repita el experimento anterior con los ejemplos de la compuerta XOR.\n",
    "\n",
    "4. Repita los experimentos con funciones de activación **ReLUs**. Que ocurre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UjbcNI0a4ac3"
   },
   "outputs": [],
   "source": [
    "# 1.1)\n",
    "\n",
    "def generate_examples(list_m, n_e, sigma=0.1):\n",
    "    centers = np.random.randn(len(list_m), n_e)\n",
    "    #print(centers)\n",
    "    M = sum(list_m)\n",
    "    n_s = len(list_m)\n",
    "    e = np.zeros((M, n_e))\n",
    "    s = np.zeros((M, n_s))\n",
    "    m = 0\n",
    "    \n",
    "    for c in range(n_s):\n",
    "        for r in range(list_m[c]):\n",
    "            e[m, :] = centers[c, :] + sigma * np.random.randn(n_e)\n",
    "            s[m, c] = 1 \n",
    "            m += 1\n",
    "\n",
    "    return e, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e, s = generate_examples([3, 2, 3], 2)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "colors = plt.cm.tab10.colors\n",
    "\n",
    "for m in range(e.shape[0]):\n",
    "    plt.scatter(e[m, 0], e[m, 1], c=[colors[np.argmax(s[m, :])]], label=\"\")   \n",
    "\n",
    "plt.xlabel(r'$e_{m, 1}$')\n",
    "plt.ylabel(r'$e_{m, 2}$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(h):\n",
    "    if h > 0:\n",
    "        return h\n",
    "    else\n",
    "        return 0\n",
    "    \n",
    "def d_relu(h):\n",
    "    if h > 0:\n",
    "        return 1.0\n",
    "    else\n",
    "        return 0\n",
    "    \n",
    "def sigmoid(h):\n",
    "    return 1.0 / (1.0 + np.exp(-h))\n",
    "\n",
    "def d_sigmoid(h):\n",
    "    gh = sigmoid(h)\n",
    "    return gh*(1-gh)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
